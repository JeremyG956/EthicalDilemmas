# Ethical Dilemmas faced my modern Tech

# Introduction

In these writings, we delve into the ethical dilemmas facing today's tech companies in a rapidly evolving digital landscape. As technology continues to shape and transform businesses across the globe, companies face a multitude of complex decisions with far-reaching implications. From data collection and privacy concerns to the impact of algorithms on user behavior, the ethical considerations surrounding tech practices have become more critical than ever. Join us as we navigate through these thought-provoking topics, uncovering the challenges and opportunities that lie ahead for businesses seeking to strike a balance between innovation and ethical responsibility.


# What are the ethical concerns associated with storing and analyzing user data?
  Data analytics has become a massive tool in the evolving ecosystem of information systems for companies to make more informed decisions on a customer’s needs. By understanding a customer’s needs a company may personalize ad content, recommend similar products, improve user interface, and create strategies to develop software that better meets these constraints (Frankenfield, Jake). Generally, data can be categorized into two sections, public and private data. Private data like GPS location can be used to show traffic congestion on the highway. Conversely, public data such as using a social media website can be used to predict a user’s location based on the user’s daily activity (Marie Wallace). Data ethics is defined as “the moral obligations of gathering, protecting, and using personally identifiable information and how it affects individuals.”  There are five pillars of data ethics: ownership, transparency, privacy, intention, and outcomes (5 Principles of Data Ethics for Business). This new and exciting field of data analytics creates ethical dilemmas posing the question; What steps can be taken to ethically collect and analyze user data? 
  Pillar one, ownership plays a massive role in data ethics, as personal data belongs to individuals. It is illegal and unethical to steal data that does not belong to you. A company may obtain permission to access a user’s personal data by utilizing pop-ups for cookie harvesting, or in user agreement policies. For example, Google’s main revenue segment is its online advertising, generating $147 billion in 2020, or, 80% of its annual revenue. By analyzing users’ data, Google can deliver highly effective ad campaigns, making it the largest percentage of the digital ad market share at 29% (Graham, Megan,). Other companies such as Brave Software, take a unique approach to data analytics and data ownership. Brave Software offers a web browser called Brave that includes built-in ad-blocking features, VPN, and cookie-less browsing. However, Brave differs from Google Chrome in how it obtains users’ data. In exchange for obtaining and analyzing users’ data, they pay the user in their native cryptocurrency token called Basic Attention Token (BAT) (Secure, Fast). Thus, giving users direct ownership of their data. 
  Pillar two, Transparency deals with how a company will gather, store, and utilize data. One way a company can obtain consent to gather data is by including a data tracking section in their terms and agreements. These user agreements, which are legal documents typically hundreds of pages long, must be accepted by the user to gain access to a company’s software. To accept the agreement, a user must click a check box to begin the installation process. It can be argued that by design, it is discouraging the average user from reading the user agreements, thus making the process unethical. When comparing the risk to reward, would someone spend 30 days dissecting a long and boring, user agreement or just rush through the document and hit the accept button risking a computer virus? For example, one study researched if users read user agreements by releasing a social medial app. Upon downloading the app, the user must accept the agreements. In the app’s agreements, it included a clause that stated users must give up their firstborn child to the company to use the software. The study found that every user accepted the terms and agreements because none of them had read them (Click to Agree). 
The third pillar, privacy navigates the responsibility of how a company will handle the data collected. Knowing what data to store and if it will need to be encrypted to protect a user continues to be a growing concern. As companies collect more and more user data, differentiating which data is personal or should be shared becomes harder to distinguish. Cloud storage companies, for example, may have instances where users upload lewd content or images of personal material. Should a company be able to analyze images and determine whether some files should have special encryption? Should a company be allowed to analyze users’ every image to make those judgments in the first place?
  In pillar four, the intent of what a company intends to do with a user’s data must be assessed. A company must define why a certain data point is needed and what it intends to do with the data. If the result of the data collection is to hurt others or profit off others’ losses it is unethical. In February of 2021, Robinhood went to trial for gamification of stock trading, and how it used user data to illicit behaviors from users. Robinhood’s vision was to lower the barrier to entry for retail investors. To achieve this goal, they had to change the perception of boring finance to something engaging and fun for the average user. Robinhood created an app with an amazing user experience that attracted customers by having features such as balloons when purchasing security which made it more rewarding and encouraging for users to do it again. Other features like using red and green colors to show daily price changes in portfolio value, and access options trading, added to the exciting or “addicting” aspects that encouraged user engagement were based on behavioral studies. After years of business, Robinhood was able to collect the buy and sell data of its customers. It then took this data and sold it to large investment firms that would write algorithms that could predict the buy and sell behavior of retail investors so the firm could position themselves in a way to capitalize on their analysis at the loss of the individual (Jr. John). Here a company fails to recognize that by collecting these data points and then selling them to other companies who would use this data to disenfranchise a group of investors who are already on the lower income side of investors. This Robinhood took from the poor and gave to the rich. 
  Finally, pillar five, outcome explores how data analytics may cause harm to a certain individual or group of people. Disparate impact or discrimination against a group of people is unlawful in the United States. The Civil Rights Act of 1964 made it illegal to discriminate on the basis of race, color, religion, sex, or national origin making it extremely important to understand how data analytics will affect users (5 Principles). One form of questionable and unethical data analytics is the use of predictive policing technology. This software analyzes police reports to identify areas in the city that have higher areas of crime so law enforcement members may station themselves at these hot spot locations and prevent or make arrests of criminals. The problem is, in an inherently biased law enforcement system like in America resulted in over-policing in minority and low-income areas while perpetuating the data to further the confirmation bias (Raji, Deborah.). Despite white people and people of color communities committing crimes at the same rate, minorities were being negatively impacted and discriminated against by “innovative” data analytics technology. 
Access to data allows for strong analytics that can place a company ahead of the competition. Cutting off access to certain data can inhibit the performance of a company, but a company can ethically store and capture users’ data if they follow the five pillars of data ethics. I believe the best way to actively acquire user data is by increasing data privacy laws that call for enforcing greater transparency. One example would be doing away with current user agreements and including interactive slide shows that give easily consumable information.




	 
Citations:
1.	“5 Principles of Data Ethics for Business.” Business Insights Blog, 16 Mar. 2021, https://online.hbs.edu/blog/post/data-ethics.
2.	“Click to Agree with What? No One Reads Terms of Service, Studies Confirm.” The Guardian, Guardian News and Media, 3 Mar. 2017, https://www.theguardian.com/technology/2017/mar/03/terms-of-service-online-contracts-fine-print.
3.	Frankenfield, Jake. “Data Analytics: What It Is, How It's Used, and 4 Basic Techniques.” Investopedia, Investopedia, 9 Sept. 2022, https://www.investopedia.com/terms/d/data-analytics.asp. 
4.	“Marie Wallace: Privacy by Design: Humanizing Analytics.” Global Privacy and Security By Design, 22 July 2016, https://gpsbydesign.org/marie-wallace-privacy-by-design-humanizing-analytics/. 
5.	Graham, Megan, and Jennifer Elias. “How Google's $150 Billion Advertising Business Works.” CNBC, CNBC, 13 Oct. 2021, https://www.cnbc.com/2021/05/18/how-does-google-make-money-advertising-business-breakdown-.html. 
6.	Jr., John. “Gamification: Why Do We Care about Robinhood? What Could the SEC Realistically Do?” New York Law Journal, 17 Nov. 2021, https://www.law.com/newyorklawjournal/2021/11/17/gamification-why-do-we-care-about-robinhood-what-could-the-sec-realistically-do/?slreturn=20220811232846. 
7.	Raji, Deborah. “How Our Data Encodes Systematic Racism.” MIT Technology Review, MIT Technology Review, 21 Jan. 2021, https://www.technologyreview.com/2020/12/10/1013617/racism-data-science-artificial-intelligence-ai-opinion/.
8.	“Secure, Fast & Private Web Browser with Adblocker.” Brave Browser, 7 Sept. 2022, https://brave.com/. 


# The Ethics of The Sharing Economy
  The sharing economy is an economic model defined by its peer-to-peer (P2P) network where users share access to goods and services, often in a similar geographical area or community. The sharing economy involves short-term P2P transactions over assets that are not being used by the owner at an agreed-upon time to loan out to others. As the internet continues to evolve, the sharing economy has grown considerably by allowing asset owners to quickly and easily find individuals who need services. (Team, T). Uber, for example, is a company that offers an online platform that facilitates connecting users who are willing to loan out their cars to users who need rides to locations. While Airbnb offers an online platform connecting users who are looking to rent another user’s home for a given time frame (Uber). As the sharing economy continues to grow, many regulatory concerns have risen from already established companies arguing that they are over-regulated and thus being undermined by their competitors through lower prices. By understanding how hotel and taxi regulations emerged, we can compare them to Uber and Airbnb’s emergence, to determine what aspects of Uber and Airbnb need tighter regulation.
	Amongst those who argue Uber should face stronger regulation are taxi drivers and taxi interest groups. In 2015 I interned for El Paso’s city government. I oversaw a city council meeting where taxi lobbyists argued to prevent the expansion of Uber into El Paso. They argued that taxi companies were required by law to carry additional insurance policies and have drivers undergo rigorous background checks to protect the consumer. Not only did regulation protect the consumer, but it guaranteed a minimum wage for workers as well. To maintain a profitable business model, they needed to charge a higher fare price discouraging consumers from using taxi services. Finally, since taxis and Uber contractors provided the same service, they should be regulated equally. By arguing these points, they were able to temporarily stop Uber from expanding into El Paso. Although insurance policies and driver safety are strong arguments, understanding the emergence of taxi regulation can depict if the same regulation should be applied to Uber. The taxi industry emerged as a faster, more convenient mode of transportation compared to horseback. As a result, users didn’t have to finance a vehicle and could now pay a small fee to move around the city more conveniently. Taxi regulation emerged in New York during the early 1930s following the Great Depression when unemployment soared, and people were desperate to make money. As competition for customers grew, prices tanked, making the business model unprofitable. Taxi companies then called for regulation. The Haas Act passed in 1937, which placed a cap on the number of taxis allowed in New York to 13,500. The act opened the door for regulation calling for greater insurance and vehicle quality. The Haas Act is largely seen as a failure by overregulation. Consumers faced greater competition to find a taxi, causing prices to surge, making taxis unaffordable, and ultimately harming the consumers (Rubenstein, D). 
	Like the taxi industry, it is imperative to understand the hotel industry’s history. Hotels have been operating since 15,000 BC, as the growth of travelers needing a place of lodge grew. Modern hotels emerged post-WWII as organizations began to offer greater luxury and higher quality of service aimed toward higher-income clients. The explosive growth of hotels called for greater regulation as monopolies grew, allowing established organizations to outbid small businesses for lots and hotel properties. The under regulation of the hotel industry became a concern as hotel owners quickly dominated the real estate markets (Bonvin, L).
Lobbyists arguing for the regulation of Airbnb come from health and safety perspectives. Hotels must regularly undergo health inspections, to adhere to city guidelines. For example, mold is a common arguing point because the cost of keeping mold levels low is expensive. From a spill on a rug to a pipe burst or leak, all these aspects of the building must be inspected and maintained regularly. Additionally, the safety quality of a building is higher in commercial buildings vs. residential buildings by more regular inspections. So, when Airbnb is continuing to grow in popularity for providing the same service – a place to lodge, homeowners can charge less for this service because they do not have to undergo the same standards and testing procedures. Furthermore, homeowners using Airbnb may be eliminating homes from the market as more people continue to see it as a business venture, causing housing prices to become more unaffordable (30, S). While those in favor of no Airbnb regulation argue that from a regulatory standpoint, it is unfeasible and unconstitutional from a privacy perspective to have the same regulations for all households in America. Sending inspectors to test for health and safety constantly would be an enormous financial burden to homeowners (or taxpayers) looking to make side money. Also, it could be argued that city home inspectors do assure these safety and health practices are up to code.
	Ultimately, the sharing economy should be viewed as a model that results in a more sustainable world. Thus, hurting companies involved in the sharing economy would not be ethical from an environmental stance. However, despite being environmentally friendly, they should not be void of regulation. When drafting legislation, it is important to not disenfranchise capital formation for small business owners, while assuring consumer protection through rigorous safety and health standards. At its core, regulation should not allow for monopolies. Failure to regulate Uber and Airbnb could allow for the systematic dominance of the sharing economy to completely crush the hotel and taxi industry. Uber and Airbnb in turn, will be given the capacity to freely dictate prices or increase their share of profits whenever they see fit.
	In conclusion, Uber and Airbnb should face similar regulations the taxi and hotel industries are facing, for some aspects. Consumer protections are the number one priority, and thus safety must always be regulated. Uber contracts should undergo detailed background checks like taxi drivers. Furthermore, vehicle safety, inspections, and full coverage insurance policies must be up to date. Uber contractors shouldn’t be excluded from certain locations just because they are taking greater market share. Airbnb on the other hand should be regulated for mold and structural integrity just as hotels are. Just because regulation may be difficult, doesn’t bode as a strong argument. Imagine if gas pumps were not regulated just because it was considered difficult, there would be chaos in many aspects of our life. Nonetheless, policies such as caps on the number of operators should not be implemented on sharing economy platforms because they will negatively impact small business owners. In a free market, fostering healthy competition is essential, and existing organizations must adapt to better meet consumer demand. 
 
Citations:
1.	30, S., Cohen, S., FitzGerald, D., & Blukis, U. (2018, August 02). Regulating the sharing economy: Uber and airbnb. Retrieved September 18, 2022, from https://news.climate.columbia.edu/2018/07/30/regulating-sharing-economy-uber-airbnb/
2.	Bonvin, J. L. (2003, December 14). Hotels: A brief history. Retrieved September 18, 2022, from https://www.hospitalitynet.org/opinion/4017990.html
3.	RUBINSTEIN, D. (n.d.). Uber, lyft, and the end of taxi history. Retrieved September 18, 2022, from https://www.politico.com/states/new-york/city-hall/story/2014/10/uber-lyft-and-the-end-of-taxi-history-017042
4.	Team, T. (2022, February 08). Sharing economy. Retrieved September 18, 2022, from https://www.investopedia.com/terms/s/sharing-economy.asp
5.	Uber, Airbnb, and the Revolution of Business. (2022, July 29). Retrieved September 18, 2022, from https://onlinemasters.ohio.edu/blog/uber-airbnb-and-the-revolution-of-business/

# Access To The Dark Web Should Be Restricted Yet Readily Available
  The internet and the content in it can best be illustrated as an iceberg. At the peak above the water is the mainstream Internet such as YouTube, Reddit, and other common high-traffic websites, known as the clear web. They can be found using just a basic Google search and are indexed for users to easily find the page. Underneath the water and containing most of the mass of the internet, is the unindexed portion, or the deep web. On the deep web, there are pages that are behind paywalls or pages that require login credentials before accessing the content. These pages may contain fee-based content, membership website, or confidential company materials. The purpose is to prevent the average internet query or internet user from finding and using the content on the page. Beyond the deep web lies the dark web, which requires a browser called Tor to access. Dark web websites are denoted with a. onion domain suffix and are characterized by a high degree of anonymity due to relaying internet traffic through a series of tunnels to prevent IP addresses from being identified. Due to the nature of anonymous browsing, the dark web fosters a safe place for illegal activities to take place such as the sale of firearms, drugs, login credentials to individuals’ financial applications, and social security numbers to name a few. More heinous activities such as hiring an assassin, accessing child pornographic content, and torture websites can be found. However, not all dark web content is illegal, as dark web access has been used during civil wars to side-step oppressive governments and continue communication with the outside world (Guccione, D). The duality in nature of the dark web creates an ethical dilemma when considering its usage. Access to the dark web should be restricted by agencies that have a vested interest in keeping their user’s data safe, but access to the dark web should be encouraged by vigilantes and users who demand greater privacy protections. 
	Government agencies have a vested interest in restricting access to the dark web or regulating what content is accessed. A study by King’s College in London found that 57% of all dark web pages host illicit material (Guccione, D). A greater percentage of illegal activities make the dark web more nefarious and harmful than beneficial, reason enough to discourage greater access. Another reason is the buying and selling of registered firearms, which have government processes to ensure owners are properly held responsible in case of an incident. Furthermore, all these drug and firearm transactions are not being placed under proper tax laws, causing financial damage to government agencies. Despite the previous points, the government is attempting to harness the power of the dark web. DARPA, or the Defense Advanced Research Projects Agency, is a government agency under the U.S. Department of Defense that launched the Memex program. The Memex program’s goal is to develop search engine software that allows for browsing the deep web and clear web simultaneously. The software would allow military, government, and commercial organizations to view what sensitive information has been leaked at any given moment. Moreover, the software seeks to tackle human trafficking, a form of slavery that is illegal under the U.S. Constitution. Although efforts have been made to greater understand the dark web, their results have been lackluster. In January of 2021, plans to raid the U.S. capitol were publicly posted on far-right websites on the dark web. Later, U.S. leaders’ and elected officials’ lives were at risk by far-right terrorist groups looking to keep former president Donald Trump in office (Wamsley, L). If searching capabilities were strengthened, and greater understanding, the events that unfolded could have been prevented. Lastly, the launch of a program to further deep web searching capabilities indicates the government has lost control and must now deal with it head-on instead of ignoring it. The Memex programs’ software does not seek to deanonymize the services, admitting they see a benefit in anonymity (Memex). 
	On the other hand, vigilantes, and advocates for individual privacy should encourage the use of the dark web. Many of the far-right websites emerged due to platforms such as Twitter and Facebook kicking off users with “extremist” views. These organizations argued their freedom of speech was being infringed upon and thus moved their discussions to the dark web (Wamsley, L). In the far-right scenario, however, freedom of speech is not protected when inciting violence. Another instance is in Iran, where they are currently protesting for women’s equality. During times of civil unrest, the government is known to slow down the spread of information by disabling internet services. Internet shutdowns allow for only SMS messages to be sent, and thus are easily monitored by government bodies to swiftly find and eliminate uprisings before they manifest. Iranians then use VPNs and dark web access to remain anonymous and securely distribute information (Sykes, P). Other groups who should encourage dark web access are privacy advocates. They may argue that nefarious websites on the dark web that sell confidential information do pose a risk to governments and companies, but the data would not be for sale in the first place if tech companies did not collect the data in the first place. If all users had a greater degree of anonymity, they would not be able to harvest data points that pose greater security risks such as cookies and search history. Current business models allow for the selling of any data collected to other companies without your consent, for other agencies to pull in greater data, ultimately creating a list of services and goods that could be used for more advanced, targeted phishing techniques, to acquire even more sensitive user data (Klosowski, T). Furthermore, as laws continue to lag technological trends, the damage to users has been greatly done, and cannot be undone. Just this year Google was fined 4.34 billion euros for violating privacy laws in France. This time, for not having a clear way for users to disable the collection of certain cookies (Person). Google and other gigantic tech firms have paid billions of dollars in fines for illegally collecting data. Privacy advocates may continue to argue that current fines are not enough as current business models only need to harvest data once before feeding it to AI for greater analysis and sale of personal data. If 4.34 billion euros is the cost of business to a trillion-dollar industry, there is no real incentive to stop the illegal harvesting of data. 
	In conclusion, the dark web offers positive and negative aspects to its usage. Government agencies should not enable wider access to the dark web as it undermines government authority, compromises the status quo, and diminishes tax revenue from sales of goods. Vigilantes and privacy advocates should push for wider dark web access to the dark web because of tech giants like Google and Meta’s risk-free business models to collect and sell personal data at the expense of its users. Ultimately, it is up to the user what content they will access, and the dark web offers both pros and cons to its usage.        
 
 Citations
1.	Guccione, D. (2021, July 1). What is the dark web? how to access it and what you'll find. CSO Online. Retrieved September 25, 2022, from https://www.csoonline.com/article/3249765/what-is-the-dark-web-how-to-access-it-and-what-youll-find.html
2.	Klosowski, T. (2021, September 6). The State of Consumer Data Privacy Laws in the US (and why it matters). The New York Times. Retrieved September 25, 2022, from https://www.nytimes.com/wirecutter/blog/state-of-privacy-laws-in-us/  
3.	Memex (Archived). Defense Advanced Research Projects Agency . (n.d.). Retrieved September 25, 2022, from https://www.darpa.mil/program/memex 
4.	Person. (2018, July 18). Timeline - Google's antitrust cases in Europe. Reuters. Retrieved September 25, 2022, from https://www.reuters.com/article/uk-eu-google-antitrust-timeline/timeline-googles-antitrust-cases-in-europe-idUKKBN1K81CB 
5.	Sykes, P., Seal, T., & Shahla, A. (2022, September 23). Iran protests: Iranians race to get online in web blackout; elon musk eyes fix. Bloomberg.com. Retrieved September 25, 2022, from https://www.bloomberg.com/news/articles/2022-09-23/iranians-race-to-get-online-in-web-blackout-musk-eyes-fix 
6.	Wamsley, L. (2021, January 8). On far-right websites, plans to Storm Capitol were made in plain sight. NPR. Retrieved September 25, 2022, from https://www.npr.org/sections/insurrection-at-the-capitol/2021/01/07/954671745/on-far-right-websites-plans-to-storm-capitol-were-made-in-plain-sight 


# Web Analytics Is A Clear Invasion Of Privacy
  Web analytics is a standard business practice and is defined as the collection, reporting, and analysis of website data. A business will obtain data from its users as they utilize the website and strategically analyze it to meet business needs such as improving the user interface or assuring website quality and functionality. Additionally, data can be used to gain market research and a competitive edge in the information that a rival company may not have (Department). As databases continue to grow with users’ information and analyzing capabilities continue to advance people fear their data may fall into the wrong hands or be used for ill intent. An invasion of privacy is illegal and defined as an unwanted individual or business into the private affairs of a person without consent (Duotribe). Web analytics is legal because users provide consent when entering a website by enabling cookies or agreeing to a website’s terms of agreement document.  Although web analytics has proven to be critical to web development, capturing data is an invasion of privacy and should not be performed because standard data capturing methodologies have overstepped their bounds on the type of data they collect, do not provide informed consent, and do not provide adequate security to protect their collected data.
  Visiting a website generates metadata, which is data about data. Metadata can be used to describe, locate, or explain data (Cofield, M). Some metadata is default such as what device you are using when you download an app, or what browser you are using when you access a website. This data is innate because it is derived from the compatibility of code. In the early 1990s when web analytics began, it started as a way of measuring website traffic and counting how many users visited the page to better valuate their performance when a company went public through an initial public offering (IPO). Today web analytics has become a trillion-dollar industry via increased capabilities to capture data and segment marketplaces for strategic gain. As the internet developed from text only to including videos and images the need for web analytics grew now that users were able to interact with the website (Leady). Now companies track every action taken by a user, from the amount of time spent on a page, which elements were interacted with, and where a user’s mouse scrolled (Department). Companies not only collect the data for their own use but can sell it to other companies looking to utilize the data. This data belongs to an individual and using that data without their permission is theft, especially if companies are profiting off the data and no rewards are being shared with the user. 
  Secondly, companies should not be performing web analytics because they cannot secure the data and expose users to greater levels of threat. Collecting and aggregating massive amounts of data immediately puts a target on companies for hackers looking to acquire sensitive information in a centralized location. It is expected for cybercrime to cost $10.5 trillion by 2025. Nearly all companies have been hacked in some manner leaking sensitive information. In 2018 an FBI special agent stated that every American citizen should expect all their personally identifiable information to be stolen and on the dark web (Morgan, S). Effectively, everybody has had their privacy invaded, and at no recourse or policies to protect consumers. With stolen data, hackers can find ways to engineer more sophisticated phishing attacks, falsify credit cards to make purchases or open accounts under someone else’s name. Damage can be worse if the data is medical records or private documents. If a company cannot secure user data, they have no right to it. 
  Lastly, an invasion of privacy involves consent but in almost all instances, there is no informed consent from the users. To obtain consent, a pop-up appears on the web page asking for permission to use cookies. What cookies, and what will be done with those cookies is never discussed in the pop-up, thus although a person is consenting to the cookies, they are not informed about what will happen with said data. Another form of consent is agreeing to the terms of use when accessing someone’s web page. The terms of service are always hundreds of pages long, and by design intended for users to skip over the lengthy legal document and just hit accept. Again, users are consenting to the terms of service, but because it is designed to be difficult to read and lengthy a user cannot adequately make informed consent. Moreover, it can be argued that because there is not much competition among companies providing web services, you are coerced into accepting a company’s data harvesting policies if a user needs a specific software package. The monopolizing of the tech industry has allowed companies to push users to accept the terms of service or not utilize powerful tools that are copyrighted so no alternatives may be available. Companies then collect the data and further their monopoly against smaller companies by selling the data to other companies or gaining a competitive advantage against the competition. 
  In conclusion, web analytics has proven to be a critical component in improving business performance, offering additional streams of revenue, and gaining a competitive advantage over the competition. However, there is no governing body of ethics for data analytics and no clear guidelines have been given to determine what data should or should not be collected. Due to the lack of ethical standards for web analytics, companies have now overstepped their place and now track every possible aspect of users, leading to a clear violation of privacy. Not only have they breached customer privacy, but they fail to protect the collected data and place users at greater risk of financial or reputational damage. It is for these reasons that capturing usage data for web analytics should not be allowed or undergo strict regulations to better protect users. 


 
Citations
1.	A brief history of website analytics. Leady.com - B2B lead generation. (2020, June 5). Retrieved October 9, 2022, from https://leady.com/blog/a-brief-history-of-website-analytics/ 
2.	Cofield, M. (n.d.). Metadata basics: Introduction. LibGuides. Retrieved October 9, 2022, from https://guides.lib.utexas.edu/metadata-basics/intro 
3.	Department of Health and Human Services. (2013, October 8). Web analytics basics. Usability.gov. Retrieved October 9, 2022, from https://www.usability.gov/what-and-why/web-analytics.html 
4.	Duotribe. (2018, September 18). Is invasion of privacy a crime? Hutcherson Law. Retrieved October 9, 2022, from https://hutchersonlaw.com/invasion-privacy-crime/ 
5.	Morgan, S. (2021, April 27). Cybercrime to cost the world $10.5 trillion annually by 2025. Cybercrime Magazine. Retrieved October 9, 2022, from https://cybersecurityventures.com/hackerpocalypse-cybercrime-report-2016/ 
6.	Stanger, K. (2017, July 18). Consent forms V. informed consent. Holland & Hart LLP. Retrieved October 9, 2022, from https://www.hollandhart.com/consent-forms-v-informed-consent 

# How Society May Deal With Cyberharassment
  Cyberharassment is defined as online harassment or online abuse targeting an individual or online group via harmful behavior. Cyberharassment is now illegal in some form across all U.S. states, decided upon by state laws. There are also several levels to the harassment such as severe, such as death threats or publishing home addresses (doxing), pervasive, or a steady number of incidences. Cyber harassment typically takes place online through emails and social media platforms. Common forms of cyberharassment include cyberbullying, cyberstalking, denial of access, denial of service, hacking, impersonation, phishing, swatting, and revenge porn (Pen America). The many forms of cyber harassment mean that is not limited to individuals, but companies can become the focus of cyber harassment as well through the denial of internal resources and prevention of accessing web pages. Focusing on the individual level, cyberharassment may be caused by “trolls”, or users who engage in dialogue to incite arguments or spread false information on forums and social medial platforms. Trolls may often hide their true identities using VPNs, gateways, and dark web platforms, making those who cause the crimes difficult to prosecute by a court of law. Cyberharassment groups have caused 74 million individuals a financial loss of $32 billion, and companies a loss of $450 million in 2005 alone. Due to the difficulty of prosecuting cyberharassment and the increasing growth of antisocial behavior online, society is faced with a hemorrhaging problem that must be addressed. To reduce cyberharassment, society must stigmatize antisocial behavior, legislate for more strict punishments nationwide, and increase cybersecurity. 
  Societies have a massive role in developing norms or the physical, social, and personal behaviors of individuals shaped by societal written and unwritten rules. Thus, to decrease cyberharassment, education, and awareness of the damages caused by cyberharassment on a large scale can increase the stigma against cyberharassment (Kallagren). Some of the large impacts stemming from cyber harassment that demand more attention are the damages done to young teens through the form of cyberbullying. Recent surveys indicate that 95% of teens in the U.S. are now online, and of those, 37% have been bullied online. Only 1 in 10 teens will tell an adult about their abuse, while the remaining will choose to not report it and hide it from their adult guardians. Populations such as LGBTQ, and women are at higher risk of facing cyberbullying (11 Facts). Acknowledging that there is a massive failure to report incidents faced by teens is a great first step to changing societal norms, as you can have an important dialogue on developing processes that make reporting incidents easier and more frequent. Additionally, a link between cyberbullying from teens and suicidal thoughts/tendencies has been seen across many studies (Hinduja). Fully explaining the implications of cyberharassment, even when behind a screen and anonymous, have serious consequences. Education is the foundation of systemic change, and more information must be distributed to young teens as young as possible.
Secondly, for society to bring about change, the U.S. must create comprehensive legislation to tackle cyberharassment and adequately punish users. There are no federal laws that directly address bullying, and punishments are determined by state laws. The only time cyberbullying may involve federal laws is when discriminatory harassment is involved. In this case, Title IV of the Civil Rights Act of 1964 will apply to protect individuals based on race, sex, gender, religion, or disability (Assistant Secretary). The issue of no federal laws leads to a lack of legal precedence, previous legal cases that guide state decisions during cases, and a lack of baseline punishments for individuals who cyber harass. The lack of legal precedence allows individuals to be sent free through loopholes, or grey areas not fully encompassed by state laws. Society members will not change their behavior if they feel nothing will happen to them for doing wrong.
  Lastly, increased cybersecurity is amongst the necessary actions that must be taken by society to deal with cyberharassment. Cyberharassment has now become a matter of national security. Just two weeks ago, the FDA had to release a statement to not cook chicken in NyQuil because users on TikTok started a trend. Understanding that TikTok is a Chinese-based company, and not knowing who started the trend, which is aimed at causing individuals harm, or why the algorithm got that challenge to trend so hard in the U.S. is a concern of national security. There has been growing speculation that the TikTok algorithm is different in the kinds of content it promotes in China vs the U.S. Chinese TikTok algorithm is thought to promote STEM-related topics, while the U.S.’s is said to promote more dancing and pranks. Furthermore, Russian propaganda and the alt-right have been linked to each other. From 2015-2017, 3507 Facebook ads have been identified as Russian propaganda targeted to the alt-right to promote “anti-white” ideology that ultimately is used to fiercely divide the country into political topics like immigration and spur hate towards people of color (DeLany, M. E.). 
  In conclusion, societies must embrace the fact that we are now in a digital age, and just as much bad will come with the good as we advance our technologies. Often legislation lags behind technological advances and the U.S. must move quickly to identify emerging threats to position itself accordingly. Not only does cyberharassment cause damage to individuals, but also to companies and jeopardizes national security. To successfully combat cyberharassment, and trolling, societies must create comprehensive legislation to adequately punish offenders, stigmatize cyber harassment through education and awareness, and increase cybersecurity measures across the board to eliminate as much foreign intervention as possible. The internet has now become a critical infrastructure, and greater regulation is essential to harnessing its seemingly unlimited potential.  
Citations
1.	11 facts about cyberbullying. DoSomething.org. (n.d.). Retrieved October 16, 2022, from https://www.dosomething.org/us/facts/11-facts-about-cyber-bullying 
2.	Assistant Secretary for Public Affairs (ASPA). (2021, October 6). Federal laws. StopBullying.gov. Retrieved October 16, 2022, from https://www.stopbullying.gov/resources/laws/federal 
3.	DeLany, M. E. (2019, May 3). "The south will rise again, Russia is our friend": The Russian Propaganda Campaign (2015-2017) and the alt-right movement in the US. MARS Home. Retrieved October 16, 2022, from http://jbox.gmu.edu/handle/1920/11517 
4.	Hinduja, S., & Patchin, J. W. (n.d.). Bullying, cyberbullying, and suicide. Taylor & Francis. Retrieved October 16, 2022, from https://www.tandfonline.com/doi/full/10.1080/13811118.2010.494133?scroll=top&needAccess=true 
5.	Kallgren, C. A., Reno, R. R., & Cialdini, R. B. (n.d.). A focus theory of normative conduct: When norms do and ... . Sage Journals. Retrieved October 17, 2022, from https://journals.sagepub.com/doi/abs/10.1177/01461672002610009 
6.	Pen America. (2022, April 5). Defining "online abuse": A glossary of terms. Online Harassment Field Manual. Retrieved October 16, 2022, from https://onlineharassmentfieldmanual.pen.org/defining-online-harassment-a-glossary-of-terms/ 
7.	Saini, H., & Rao, Y. S. (n.d.). Cyber-crimes and their impacts: A study. Retrieved October 17, 2022, from https://www.researchgate.net/profile/Hemraj-Saini/publication/241689554_Cyber-Crimes_and_their_Impacts_A_Review/links/5422a5d00cf290c9e3a9ee9d/Cyber-Crimes-and-their-Impacts-A-Review.pdf 


# IoT Devices, The Good, The Bad, The Ugly
  The Internet of Things (IoT) is an emerging sector of technology that has seen explosive growth in recent years through the advancement of wireless sensor network (WSN) sensors manufacturing and data transfer capabilities. IoT devices are sometimes called smart devices and are characterized by a machine’s ability to connect to the internet thus receiving and transmitting data (Alfandi). Devices such as drones, watches, and home appliances are becoming increasingly smarter generating vast amounts of data faster than ever before. IoT devices transcend the cyber-physical worlds by allowing users to operate drones remotely for firefighting, use a watch to monitor heart rate in real-time or start laundry by pressing a button on an app. As IoT devices continue to advance, the data collected continues to become more personalized, jeopardizing users’ privacy.  Furthermore, vulnerabilities against hackers grow to a level of national security as more IoT devices circulate into most American households. With the data generated from IoT devices, companies can better improve their services by tailoring services to their customers and creating more ease for individuals. The data collected is sold to other organizations who create or already manufacture similar products to see if they can identify trends that allow their organization to strategically plan business goals. The data sold, however, belongs to individuals who generate the data but is sold by the organization implying organizations have ownership of the data. Not always is the data sold, but smartwatches such as Fitbit give the data to the U.S. government for agencies to extrapolate health data from Americans. Through Fitbit data, for example, health agencies in America can better understand the population’s needs and plan for future resource allocation. However, some argue that the purchase of an IoT device does not give consent to the selling of your data to third parties, only the tracking. Others argue that certain items do imply consent such as a Fitbit because it is marketed as a heart monitor, distance monitor, and overall health wellness app that you must willingly attach to your body. Fitbit’s privacy policy states “We may preserve or disclose information about you to comply with a law, regulation, legal process, or governmental request; to assert legal rights or defend against legal claims; or to prevent, detect, or investigate illegal activity, fraud, abuse, violations of our terms, or threats to the security of the Services or the physical safety of any person” (Rodis, A). Fitbit’s privacy policy has thus lead to many arrests through monitoring of heart services data to identify criminals in murder cases. Many argue that distributing data to the authorities is a violation of the 4th amendment or the protection against unreasonable searches and seizures without warrants. The allowed selling or sharing of data with certain organizations vs others also implies that data sharing is okay with some organizations but not others (Rodis, A).
	Despite the data risks associated with IoT devices, there is no denying the profound impact they’ve had on creating convenience for users in their everyday lives. Much to IoT devices’ success, many argue that the progress achieved in such a short amount of time is due to collaboration, and the selling or sharing of data with other organizations. Moreover, they argue that because users have agreed to the terms and conditions of the product, companies are allowed to sell the data on their own accord. Additionally, organizations are conducting data transactions under existing legal pretenses and thus are using resources to create the best products on the market (Perea, C).
	While many experts agree that data sharing creates greater insight into improving user experience and overall generates greater convenience for users, the privacy risks outweigh the current data-sharing business models. Purchasing an item such as a smart washer for the purpose of water conservation does not imply consent to sell a user’s data. Throughout a device’s lifetime, many data points may be collected that generally have no inherent value. A company may be able to further extrapolate data to interpret better delivery of services. A hacker on the other hand may use this data maliciously to determine what hours you are in the house, to plan a robbery for example. Also, the transaction of data results in multiple copies of datasets being shared. This now creates multiple points of entry for hackers to locate data and use it maliciously. 
	In conclusion, I believe that data outside of the device’s intended use should never be collected, nor should it be shared with users regardless of the organization. The sharing of data implies that two datasets exist after data sharing thus generating two points of vulnerability for hackers to reach a particular individual. Although, it may be that data can be sold stripped of identifying information, the vast amount of data points may be able to derive multiple connections to individuals (Perera, C). Too many times have companies mishandled data, and now it is suggested that every American has their personal information leaked into the dark web. Furthermore, the data industry provides a risk-free business model for organizations that will ultimately pay a small fee after breaking serious laws and seriously jeopardizing consumer data. Some blockchain-based IoT networks have made interesting adaptations to tackle data ownership and security. Blockchain is an open-sourced ledger that makes all transactions public – eliminating the possibility to hide transactions. Anonymity is tackled in how wallet addresses are created as a string of letters and numbers to remove someone’s physical identity from their internet-based wallet. Moreover, data ownership is more concrete, and users have greater control over what data can be shared with data brokers and data dealers by receiving compensation in the form of a cryptocurrency or token for the data users share (Alfandi, O). I believe that a blockchain-based system where users have direct control over their data provides a stronger model for security and informed consent of data sharing. 


 
Citations:
1.	Alfandi, O., Khanji, S., Ahmad, L., & Khattak, A. (2020). A survey on boosting IOT security and privacy through blockchain. Cluster Computing, 24(1), 37–55. https://doi.org/10.1007/s10586-020-03137-8 
2.	Karale, A. (2021). The challenges of IOT addressing security, ethics, privacy, and laws. Internet of Things, 15, 100420. https://doi.org/10.1016/j.iot.2021.100420
3.	Perera, C. (n.d.). Sensing as a service (S2aaS): Buying and selling IOT Data. IEEE Internet of Things. Retrieved October 30, 2022, from https://iot.ieee.org/newsletter/november-2016/sensing-as-a-service-s2aas-buying-and-selling-iot-data.html  
4.	Rodis, A. (2020). NOTE: FITBIT DATA AND THE FOURTH AMENDMENT: WHY THE COLLECTION OF DATA FROM A FITBIT CONSTITUTES A SEARCH AND SHOULD REQUIRE A WARRANT IN LIGHT OF CARPENTER V. UNITED STATES . William. & Mary Bill of Rights Journal.

# In-house Databases vs SaaS Option Exploration for Businesses
  Before Microsoft, Google, and Amazon offered mobile applications for business operations all IT operations were performed in-house, and organizations would have to pay the costs of all hardware and software in addition to housing and operational fees. Fees associated with in-house databases include initial installation costs such as hardware and software licenses, labor expenses for control panels, servers cost, and server software. Still, there are additional hidden fees for in-house databases such as electrical power, rack space, IT staff costs for routine maintenance, troubleshooting, installing patches, and cost of upgrades or parts replacement making the total cost of ownership multiples higher than the initial investment (Till, S.). To tackle the increasing costs of IT management, Software as a Service (SaaS) has become an increasingly popular cloud-based service for organizations to receive computing services, data storage, and software services via the internet. SaaS vendors aim to lower IT costs by actively taking care of software patches and IT management overhead, lower complexity for users, and offer greater scalability in comparison to in-house databases. As a result, companies can choose packaged software options that fit their business needs via a subscription-based model without the need to invest in data centers and IT personnel (Wu, W). Although SaaS appears to be the clear winner against in-house databases when analyzing financial costs alone, there are still aspects to consider that make in-house databases a viable decision such as customization and security. SaaS vendors offer blanketed subscription plans, whereas an in-house database can host applications that exactly meet the necessary functional requirements for a particular organization. Furthermore, because SaaS is a subscription-based plan, failure to meet payments may result in the loss of your organizational data. Additionally, due to services being delivered on demand via the internet, internet outages may completely disable business operations (Fan, H.). Ultimately, a business should decide which database solution provides the greatest competitive advantage by analyzing additional factors outside of financial metrics such as business age, tax implications, and security risks.
	New enterprises should use SaaS database solutions vs in-house databases because organizational objectives should focus on generating revenue, establishing reliability, and minimizing expenditures. Starting a new company straight out of the LLC or S-Corp filing should focus on generating revenue. It doesn’t make sense, for example, a bakery, to invest in hardware, software, and IT personnel to analyze what flavor of cookie to make based on seasonal ingredients and popular selling items. Instead, organizations in their infancy should focus on generating revenue, and SaaS can offload those IT tasks from the organization so they can focus on product sales and development (Wu, W). Moreover, a big hurdle for new organizations is establishing a reputation deserving of trust and business. A SaaS database solution can provide domain names, and designated channels for communication inside and outside of the enterprise at an extremely lower cost compared to in-house databases (Wu, W.). These channels can then be used for advertising opportunities in the form of business cards, whilst simultaneously adding structural integrity to enterprise communication portals and giving credibility to a new organization.
	Middle-aged enterprises that have established strong and diverse streams of revenue, contain more personnel of 50+ individuals, and are seeking to gain a competitive advantage against other industry participants should transition to a hybrid-based database solution comprised of SaaS and in-house databases. To get to a mid-sized organization, personnel have done an outstanding job at establishing a trusty worthy reputation. SaaS may have provided a cheap and effective method for doing so however, internet outages may freeze business processes that require software or database usage. In-house databases with limited capabilities will ensure that even though an internet outage may occur, critical business data can be accessed to complete or continue services for their customers that are dependent on them. Additionally, the costs of hardware, software, and personnel seem like a massive cost to burden for a mid-sized organization but capital expenditures for business assets may be written off entirely according to the IRS. They state that “machinery…. freight and installation charges” may be written off, making the investment of in-house databases more affordable (IRS). 
	Older, larger-sized organizations with 100+ personnel should continue with a hybrid system to allocate critical information to in-house databases while allocating less critical functions to SaaS vendors. More established enterprises have now established a strong reputation for themselves and have done something unique to set them apart from industry competitors. This unique process or product is now a point that gives a competitive advantage and should be protected from competitors. With over 80% of companies being hacked, including SaaS vendors who hold multiple enterprises’ private data, it is not safe to assume they will safeguard all your data (Duke, FUQUA). Classified documents should remain private and thus in-house databases offer the greatest level of data security by limiting access to the database via employee badges and two-factor authorization. SaaS should still be used for communication channels, as SaaS options provide excellent and encrypted messaging options for managing 100+ individuals easily. Finally, allocating all enterprise functions to in-house can be viewed as environmental waste. Monitoring and managing environmental impact should begin to rise in priority as a business becomes more established. In-house databases must be more robust to ensure outages are at a minimum and services can continue, thus organizations must over-purchase to guarantee functionality leading to IT service utilization will never reach 100% (Till, S.). 
	In conclusion, enterprises in their infancy should use SaaS databases to focus on establishing a strong reputation and developing revenue streams. Mid-sized and large-sized enterprises should use a hybrid model to take advantage of tax benefits and secure company data that has given them a competitive advantage over market competitors. Many may argue that staying with a SaaS vendor is cheaper, readily scalable, and more environmentally friendly. A hybrid-based model allows companies to take advantage of tax codes making in-house databases more affordable, ensures ownership of critical business data, ensures the continuation of essential business functions, and grants greater security of organizational data.
 
Citations
1.	Duke FUQUA. (n.d.). MORE THAN 80 PERCENT OF FIRMS SAY THEY HAVE BEEN HACKED. Duke CFO Global Business Outlook. Retrieved November 6, 2022, from https://cfosurvey.fuqua.duke.edu/press-release/more-than-80-percent-of-firms-say-they-have-been-hacked/ 
2.	Fan, H., Hussain, F. K., & Hussain, O. K. (2014). Semantic client-side approach for web personalization of SAAS-based cloud services. Concurrency and Computation: Practice and Experience, 27(8), 2144–2169. https://doi.org/10.1002/cpe.3418 
3.	Internal Revenue Service. (n.d.). Publication 535 (2021), business expenses: Internal Revenue Service. Publication 535 (2021), Business Expenses | Internal Revenue Service. Retrieved November 6, 2022, from https://www.irs.gov/publications/p535#en_US_2020_publink100078332 
4.	Till, S. V. (2008, January). SaaS vs. Server-Based Systems. Gale OneFile. Retrieved November 6, 2022, from https://go-gale-com.ezproxy.lib.uh.edu/ps/i.do?p=ITBC&u=txshracd2588&id=GALE|A174592145&v=2.1&it=r 
5.	Wu, W.-W. (2011). Developing an explorative model for SAAS adoption. Expert Systems with Applications, 38(12), 15057–15064. https://doi.org/10.1016/j.eswa.2011.05.039 


# Algorithms – The Good vs. The Bad
  Today artificial intelligence (AI) systems have been introduced into nearly every sector of business to influence decision-making based on big data through a series of algorithmic computations. An algorithm is defined as “a procedure executed by computers that convert digital input into digital output” (Yan, S.). From a user’s perspective, AI systems can use algorithms to recommend content such as which newspaper articles to read, which videos to watch, or what product gets advertised to you. From a business’s perspective, AI systems can be used for complex decision-making such as creditworthiness and credit rates for customers based on their credit history and demographic data, healthcare plans and treatment, educational opportunities, and employment opportunities via prescreening. Governments have also begun using AI systems in judicial systems to determine sentence length and bond prices, and law enforcement agencies to determine which areas need greater policing. While AI systems have been excellent at making sense of the large volume of data generated and collected, the unprecedented rise of AI systems into nearly every facet of daily life gives generates concern about bias and algorithm decision-making implementation that creates bias (Grayvette, W.). Bias is defined as “prejudice in favor of or against one thing, person, or group compared with another, usually in a way considered to be unfair.” (Yan, S.). In America, there is Equal protection which means that all individuals and groups must be subject to and treated equally under penalty of law (Grayvette, W.). Not only is bias illegal, but moral issues arise in the context of equity, justice, and most recently democracy. Social media platforms such as Facebook utilize algorithms and AI systems that filter content and are thought to create extreme polarization among groups of people. The January United States Capitol attack led far-right extremist groups to kidnap members of Congress and prevent them from certifying the 2020 presidential election results which granted Joe Biden the presidency, has proven that bias within algorithms can become a matter of national security (Offices). Although bias should be eliminated from algorithms, there are some instances where bias for decision-making algorithms in banking has arguably created greater stability in financial markets (Asonuma, T.). Ultimately, Facebook and other social medial platforms should seek to eliminate bias within their algorithms, however, decision-making algorithms that innately contain bias for decision-making, create enormous use for business and must be improved upon to eliminate any negative bias that may affect a group of people.
	Facebook and other social media platforms use their algorithms to generate interest in their feed which from a business perspective generates more usage and more profits in the form of advertisements and data harvesting users. After the January capitol insurrection, Facebook and other social media platforms were heavily scrutinized for allowing the spread of misinformation. Lawmakers quickly questioned their algorithms which are said to have fostered an environment of hate against other political parties and party members. Social media algorithms can be useful to many who are looking for great local spots to eat, recommending which friends to add, and which posts get recommended to you based on previous post interactions. The conflict is when a company wants users to generate data and advertisement revenue, they need to keep you online. Algorithms keep you online by feeding you similarly ideological content to keep you scrolling, or to show more content that has generated a response from you in the past. Lawmakers questioned if feeding similarly ideological information resulted in the deliberate prevention of viewing conflicting points of view. Preventing users from understanding other points of view is thought to foster polarization and undermine common ground for both parties – an essential part of democracy (Lazer, D.).
	Decision-making algorithms such as those used in financial sectors for mortgage calculations, credit ratings, and asset purchases are said to have bias but are favorable because of the financial stability they bring to markets through debt sustainability. For example, when a financial institution is looking to finance a mortgage, they analyze individuals’ income-to-debt ratios to quickly determine their eligibility for a home. By identifying riskier clients, they can deny them a mortgage and prevent a situation like in 2008, where millions of Americans were unable to make home payments because banks were recklessly handing out mortgages on as many properties as possible to generate revenue. The greatest exhibit of financial stability generation is in the bonds purchasing sector where algorithms analyze the relationship between home bias and borrowing costs, level of public debt, primary balance adjustment, and the level of debt at which countries enter distress to quickly identify which bonds are the safest to buy and riskier investments (Asonuma, T.). By purchasing the highest quality assets, companies and countries can safely issue and purchase/sell bonds for a sustainable debt model within the country, bringing greater financial stability.
	In conclusion,	Facebook and other social media sites should eliminate bias within their social algorithms because they have threatened national security and created users who feel addicted to their platforms. Although it can be beneficial for some users to see which is the highest-rated restaurant in their area based on data points like likes and comments, it does not outweigh the reckless fostering of hate groups that have now created terrorist attacks on American leaders and undermined American democratic processes. Still, decision-making bias should remain within financial sectors to generate economic stability so long as they don’t harm a group of people. Although some argue that credit ratings and credit rates have socioeconomic implications for marginalized groups of people, the wild issuance of mortgages and debt to individuals who cannot pay them back creates greater financial instability for the market as a whole and eventually the global market. 
 
Citations
1.	Asonuma, T., Bakhache, S., & Hesse, H. (2015). Is banks’ home bias good or bad for public debt sustainability? SSRN Electronic Journal. https://doi.org/10.2139/ssrn.2585430 
2.	Gravett, W. (2021). Sentenced by an algorithm — bias and lack of accuracy in risk-assessment software in the United States Criminal Justice System. South African Journal of Criminal Justice, 34(1), 31–54. https://doi.org/10.47348/sacj/v34/i1a2 
3.	Lazer, D. (2015). The rise of the social algorithm. Science, 348(6239), 1090–1091. https://doi.org/10.1126/science.aab1422 
4.	Offices of the United States Attorneys. (2021, December 30). One year since the Jan. 6 attack on the Capitol. The United States Department of Justice. Retrieved November 13, 2022, from https://www.justice.gov/usao-dc/one-year-jan-6-attack-capitol 
5.	Yan, S. (2021). Algorithms are not bias‐free: Four mini‐cases. Human Behavior and Emerging Technologies, 3(5), 1180–1184. https://doi.org/10.1002/hbe2.289 

# To Collect Or Not To Collect?
  Smartphone usage has now surpassed 3 billion globally and continues to grow exponentially as manufacturing capabilities continue to advance (Li, T.). With the growth in mobile phone usage comes an explosion of data collection and data mining to identify patterns and traits associated with users who are utilizing web services and better meet their needs. Additionally, smartphones connecting to IoT devices through app interfaces create even greater data-collecting capabilities and deeper user understanding as more metadata is introduced. Mobile phone applications collect core data points such as whom users communicate with and how often they communicate through call or text logs. Mobile phone applications can also collect location data directly through GPS or indirectly through metadata within Wi-Fi login data. Smartphones have now introduced web and Bluetooth capabilities allowing data collection from app usage, webpage activity, and shopping habits. Therefore, collecting smartphone data and metadata can pose a privacy issue because the data can be used to reveal behavioral, contextual, and psychological information from smartphone users. (Harari, G.) Although smartphone data and metadata collecting can be an ethical dilemma, its usage can provide smartphone manufacturers and network providers with data-driven models to forecast demand and provide a greater user experience (Li, T.). Thus, companies or individuals looking to create, for example, a weather app, face the ethical dilemma of what types of data to collect, and if additional data outside of the app should be collected to aid in future application development or for enhancing user experience. Under American jurisdiction, the types of data and metadata that should be collected depend on the organization’s size, mission, and finances. 
	If the company or individual developing a weather app is in the infancy of its business and it will be the first or one of the first five products available on the market, it should collect only the data essential to the weather app functionality. First, a start-up, or mid-sized business from a financial perspective is already in murky territory making 10 million or less a year. Their financial resources should be dedicated to maintaining business functionality and using most of their revenue to expand operations or improve business processes to gain a competitive advantage in the market. Second, and possibly most critical is to establish and maintain a strong reputation with its customers. A good reputation should remain a critical goal in all organization’s missions especially so for organizations in their infancy. Therefore, only collecting data critical to a weather app functionality such as; GPS location, the amount of time using the app, which functions the app users utilize the most, and the number of times the app is used, are acceptable because they are data points that do not inherently have a negative effect on users if compromised. 
	If the company is a large-sized organization doing billions of dollars in revenue and offering a wide range of products to the market, it should collect as much data as possible outside of the functionality of the application to better understand user demands and gain a competitive advantage. A smartphone offers a variety of sensors that continuously receive input which may be useful for future application development such as motion sensors, barometers, photometers, thermometers, accelerometers, ambient light sensors, gyroscope sensors, NFC sensors, and proximity sensors to name a few (Jay, T.). When all data aggregated together is datamined, the possibilities for improving user experience and understanding their needs are limitless. From a financial perspective, an organization of this size is financially sound, and risks should be taken to gain greater competitiveness against new and innovative market participants who are looking to disrupt the industry. Furthermore, a company of this size has established itself as a trustworthy and honorable place to conduct business, making innovation and greater customer experience the same level of priority as maintaining the company’s reputation.
	In conclusion, it is important to establish that collecting user data outside of app functionality is unethical in America because data outside of the app functionality poses a privacy threat which is protected under the U.S. Privacy Act of 1974 (Office). If data poses a security risk, it is inherently illegal to collect and store that data without proper protection measures under penalty of law. Moreover, because America is a target for cyberattacks due to the abundance of user-sensitive data, and over 80% of U.S. companies having been hacked, data collection outside of the app functionality is unethical. There simply is not enough data protection for users on a national scale. Still, despite the ethical dilemma, large organizations doing billions of dollars in revenue with valuations in the trillions of dollars do not have to worry about the repercussions of poor data collection and data protection penalties. Today, trillion-dollar companies abide by a risk-free model, where the data that they collect can be fed to AI for data mining. When fines are collected by government bodies, the fee is only for the collection of data during a given time frame, and not the number of incidents data was improperly collected. The greatest fine for violating privacy laws in America was $350 million, which is nothing but a drop in the bucket when looking at trillion-dollar companies (Hill, M.). Additionally, because trillion-dollar companies such as Google and Apple are publicly traded companies listed on the NASDAQ, they have large, vested interests by Wall Street on the behalf of American pension plans to lobby against any meaningful data privacy reform that could cause any real harm to tech giants business models (Kenebel, K.). As a result of the risk-free model for data collection and data mismanagement, although it is unethical, it is still a strong strategy for maintaining market dominance. Organizations in their infancy simply don’t stand a chance against the financial dominance and market share monopoly that more developed companies have, while simultaneously being allowed to mishandle data for such a relatively small price. Lastly, although smartphones come equipped with sensors to monitor their own environment, access to those sensors does not have to be given to the company as the weather data can be scrubbed from the internet and presented within the app. Organizations could slip gaining access to the sensors into their 100s of pages long terms of agreement and under loose definitions of improving user experience to legally allow them to harvest unnecessary data. Therefore, small companies should stick to app functionality data permissions to avoid legal conflict or jeopardize their reputation so that no one would utilize their product. Large companies, although it is unethical, can make strong arguments that it is strategic for them to collect as many data points as possible under an “improving user experience” veil.

 
Citations
1.	Harari, G. M. (2020). A process-oriented approach to respecting privacy in the context of mobile phone tracking. Current Opinion in Psychology, 31, 141–147. https://doi.org/10.1016/j.copsyc.2019.09.007 
2.	Hill, M. (2022, September 12). The 12 biggest data breach fines, penalties, and settlements so far. CSO Online. Retrieved November 27, 2022, from https://www.csoonline.com/article/3410278/the-biggest-data-breach-fines-penalties-and-settlements-so-far.html 
3.	Jay Tillu. (2019, June 12). Mobile sensors: The components that make our smartphones smarter. Medium. Retrieved November 27, 2022, from https://medium.com/jay-tillu/mobile-sensors-the-components-that-make-our-smartphones-smarter-4174a7a2bfc3
4.	Knebel, K. R. (2017, October). Wall Street Accepts (but Lobbies Against) the Fiduciary Rule. Managing 401K Plans, 25(10). https://link.gale.com/apps/doc/A539920820/AONE?u=txshracd2588&sid=bookmark-AONE&xid=e07db8ae 
5.	Li, T., Zhang, M., Li, Y., Lagerspetz, E., Tarkoma, S., & Hui, P. (2021). The impact of COVID-19 on smartphone usage. IEEE Internet of Things Journal, 8(23), 16723–16733. https://doi.org/10.1109/jiot.2021.3073864 
6.	Office of Privacy and Civil Liberties. (2022, June 14). United states code. U.S. Department of Justice. Retrieved November 27, 2022, from https://www.govinfo.gov/help/uscode

# Tech Dealings with China, Muddy Waters
  The People’s Republic of China has the world’s largest number of internet users at over 700 million users. It is through internet usage that the people of China can share information and ideas easily. Many U.S. and foreign leaders believed the internet would act as a catalyst to convert the country from communistic to democratic. However, the Chinese government has gone to great lengths to censor the content users in China can post and view. The largest internet censorship system is in China and was achieved through close workings with internet service providers, internet content providers, and the People’s Republic of China’s government (Lum, T.). The collaboration between U.S. companies and the Chinese government to limit individuals’ access to content and information has been widely criticized by many members of Congress. The restriction of information in China has led to violations related to human rights, trade and investment, and cybersecurity. Although the companies are U.S. companies, they are operating in Chinese jurisdiction and thus are protected from legal recourse through Hague Conventions from U.S. plaintiffs (Rosier, K.). The tensions from U.S. companies operating in China have resulted in the Global Online Freedom Act which required all U.S. companies to disclose any censorship or surveillance technology they provide to internet-restricting countries outside of the United States and bar U.S. companies from selling technology used for the purpose of censorship or surveillance in other countries (Lum, T.). Furthermore, to remediate censorship efforts, the U.S. hosts a wide range of workshops and educational seminars on how members of heavily censored governments can access the web freely and without being monitored or censored. Providing any technological hardware or software to China from U.S. companies has been an increasingly difficult task when trying to grapple with China’s ability to modify existing technologies for the use of censorship or for limiting other freedoms. U.S. companies should only offer hardware technology to China while keeping software to themselves. 
  Many argue that it is okay to sell technologies to China on the premise of economic Darwinism, keeping diplomatic relations, and allowing for cheaper manufacturing of goods. The first and possibly strongest argument for vending software to countries limiting Internet usage is economic Darwinism. If U.S. companies do not sell software to China, the second largest country by GDP, then other countries will. This is a huge loss financially for U.S. companies looking to achieve maximum revenue and add value to shareholders. Furthermore, if a U.S. company vends software to Ireland for example, there is no premise stopping them from turning around and vending that software to China. Rising globalization and the need to compete are why the U.S. should deal directly with China. Furthermore, doing business with China opens the floor to greater diplomatic relations with the U.S. and China. If China stopped all production of American goods, it would likely cripple the American lifestyle as we know it today. Allowing for the mutual dependence of China and the U.S. allows for greater peace and stability for both nations. Lastly, allowing the sale of hardware schematics for manufacturing purposes allows for lower costs for Americans who can use that technology to further advance the workforce by improving skills and spreading information. 
	Still, despite the associated advantages, many argue we should cut all technological deals with China completely because any tech sold to China could give to them a competitive advantage over the U.S., act as a security risk, and even hardware production could lead to large violations of human rights. First, the vending of software directly to China could lead to direct security risks as they may test for security breaches and use this to access the private data of U.S. companies. Additionally, China may use these company secrets to position itself as a global leader. For example, a Spanish company named Gamesa opened manufacturing operations in China where Chinese manufacturers then stole the blueprints to manufacture every part of its wind turbine. Now China uses those same blueprints to manufacture 80% of all wind turbines today (Bradsher, K.). This quickly alarmed U.S. foreign policymakers to and started the U.S. – China tech war under former President Trump’s administration (Sun, H.). Moreover, even allowing for only the manufacturing of hardware could lead to greater human rights violations. Such as the Apple manufacturing plant in Zhengzhou, China where workers are forced to complete grueling 12-hour workdays, receive little pay, and suicide is marginally higher. Workers live on the plant site dorms that are marketed as free housing but are forced to pay much higher water and electricity rates. Working conditions are so harsh mentally and physically that all floors in the manufacturing plant have nets to stop workers from jumping and committing suicide. Finally, even companies operating within China are forced to work with authorities and use private conversations of users such as emails or text messages to provide evidence for the arrest of individuals criticizing the government. 
	In conclusion, software should not be shared with Chinese companies, and only hardware manufacturing should be allowed to take place in China, only when the full assembly is not taken place in China. Vending software to China may prove economic prosperity in the short term, but in the long term, the security risks are too great and can lead to greater financial risk. Losing business secrets and having them used against you to create cheaper products could undermine the business as a whole and cripple an organization as a global provider. However, vending hardware and allocating hardware production to China can pose a strong economic advantage. First, on the pollution that inevitably takes place in manufacturing, which would be centralized to China and not on American soil. Second, although China may attempt to steal manufacturing secrets, this can be adverted by not allowing for key features to be created in China or having the full assembly at another location outside of China. These practices can protect business secrets to the benefit of cheap labor and materials. Rising globalization and increasing foreign dependency call for the need to have strong diplomatic relationships. Economic prosperity for both countries provides a sound channel for communication and trust-building on both sides of the world.

 
Citations
1.	Bradsher, K. (2020, January 15). How China obtains American Trade Secrets. The New York Times. Retrieved December 4, 2022, from https://www.nytimes.com/2020/01/15/business/china-technology-transfer.html 
2.	Lum, T., Figliola, P. M., & Weed, M. C. (n.d.). China, Internet Freedom, and U.S. Policy. China, Internet Freedom, and U.S. Policy . Retrieved December 4, 2022, from https://sgp.fas.org/crs/row/R42601.pdf. 
3.	Rosier, K. (2015). China’s Great Legal Firewall: Extraterritoriality of Chinese Firms in the United States. U.S.-China Economic and Security Review Commission. 
4.	Sun, H. (2019). U.S.-China Tech War. China Quarterly of International Strategic Studies, 05(02), 197–212. https://doi.org/10.1142/s237774001950012x 

